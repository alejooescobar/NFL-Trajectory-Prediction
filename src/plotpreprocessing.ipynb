{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc,no_update\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "from tensorflow import keras,data as tfdata\n",
    "from numpy import load,polyfit,linspace,poly1d\n",
    "import json\n",
    "from pandas import read_csv,DataFrame,merge\n",
    "from ast import literal_eval\n",
    "import dash_bootstrap_components as dbc\n",
    "from os import path\n",
    "my_dir = path.dirname(__file__)\n",
    "\n",
    "o_player_sequences, d_player_sequences = load(f'{my_dir}/../Notebooks/trajectories_demo.npy',allow_pickle=True)\n",
    "sequences_ordered = load(f'{my_dir}/../Notebooks/sequences_ordered_demo.npy',allow_pickle=True)\n",
    "# getting the ordered sequences from the clustering\n",
    "o_player_sequences_id = load(f'{my_dir}/../Notebooks/o_player_sequences_id_demo.npy',allow_pickle=True)\n",
    "\n",
    "with open(f'{my_dir}/../Notebooks/player_pairs_demo.json', 'r') as f:\n",
    "    player_pairs_str = json.load(f)\n",
    "    player_pairs = {literal_eval(key_str): value for key_str, value in player_pairs_str.items()}\n",
    "\n",
    "with open(f'{my_dir}/../Notebooks/player_pair_ids_demo.json', 'r') as f:\n",
    "    player_pair_ids_str = json.load(f)\n",
    "    player_pair_ids = {literal_eval(key_str): value for key_str, value in player_pair_ids_str.items()}\n",
    "\n",
    "player_pair_ids = {k:v for k,v in player_pair_ids.items() if v}\n",
    "\n",
    "trajectory_dict_keys = DataFrame(list(player_pair_ids.keys()),columns=[\"gameId\",\"playId\"])\n",
    "bdb_games = read_csv(f'{my_dir}/../NFLData/games.csv')\n",
    "bdb_plays = read_csv(f'{my_dir}/../NFLData/plays.csv')\n",
    "bdb_players = read_csv(f'{my_dir}/../NFLData/players.csv')\n",
    "valid_games = trajectory_dict_keys[[\"gameId\"]].drop_duplicates()\n",
    "valid_plays = trajectory_dict_keys[[\"gameId\",\"playId\"]].drop_duplicates()\n",
    "\n",
    "valid_games = merge(bdb_games,valid_games,on=\"gameId\",how=\"inner\")\n",
    "valid_plays = merge(bdb_plays,valid_plays,on=[\"gameId\",\"playId\"],how=\"inner\")\n",
    "\n",
    "\n",
    "with open(f'{my_dir}/../Notebooks/all_trajectory_dict_demo.json', 'r') as f:\n",
    "    all_trajectory_dict_1_json = json.load(f)\n",
    "    all_trajectory_dict = {literal_eval(key_str): value for key_str, value in all_trajectory_dict_1_json.items()}\n",
    "\n",
    "\n",
    "o_padding_value = [-1.0 for _ in range(len([o_player_sequences[0][0]]))]\n",
    "padded_o_seq = keras.preprocessing.sequence.pad_sequences(o_player_sequences,padding='post', value=o_padding_value, dtype='float32',maxlen = 90)\n",
    "masking_o_layer = keras.layers.Masking(mask_value=-1)\n",
    "masked_o_seq = masking_o_layer(padded_o_seq)\n",
    "\n",
    "padding_value = [-1.0 for _ in range(len([d_player_sequences[0][0]]))]\n",
    "padded_d_seq = keras.preprocessing.sequence.pad_sequences(d_player_sequences,padding='post', value=padding_value, dtype='float32',maxlen = 90)\n",
    "masking_layer = keras.layers.Masking(mask_value=-1)\n",
    "masked_d_seq = masking_layer(padded_d_seq)\n",
    "prev_clicks = 0\n",
    "o_x, o_y,d_x,d_y = [],[],[],[]\n",
    "los_x_arr,los_y_arr = [],[]\n",
    "o_marker_colors = ['rgb(200, 200, 255)']\n",
    "d_marker_colors = ['rgb(200, 255, 200)']\n",
    "cluster_options = [{'label': f'Cluster Center {i+1}', 'value': i} for i in range(8)]\n",
    "cluster_center_options = [{'label': f'Sequence {i+1}', 'value': i} for i in range(8)]\n",
    "game_options = []\n",
    "for row in valid_games.itertuples():\n",
    "    game_options.append({'label':f'{row.homeTeamAbbr} vs. {row.visitorTeamAbbr} playing home to {row.homeTeamAbbr} on {row.gameDate}','value':row.gameId})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
